{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts accompany the blog post [title] found on the Fugitive Leaves blog of The Historical Medical Library of The College of Physicians of Philadelphia.\n",
    "\n",
    "[link to blog post]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These libraries, which are prepacked sets of modules and functions that provide specific functionality not present in the core Python library, are necessary for running the scripts that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import urllib.request\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing text from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign the URL you want to a variable\n",
    "#this is the URL for the plain text version of volume 56 of The West Virginia Medical Journal \n",
    "journalUrl = \"https://archive.org/stream/westvirginiamedi5619west/westvirginiamedi5619west_djvu.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assign the plain text to a variable as a string\n",
    "journalString = urllib.request.urlopen(journalUrl).read().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines clean the Internet Archive header and footer from the raw text string. This is not covered in depth in the post, but is mentioned. Cleaning up texts is always case by case and involves checking your results after each manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove header and footer\n",
    "header = journalString.find('<pre>') + len('<pre>')\n",
    "footer = journalString.find('</pre>')\n",
    "journalString = journalString[header:footer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenize and make each word lowercase\n",
    "journalTokens = nltk.word_tokenize(journalString.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['•',\n",
       " \"'\",\n",
       " 'bd',\n",
       " '?',\n",
       " '.',\n",
       " '5.05',\n",
       " 'digitized',\n",
       " 'by',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'archive',\n",
       " 'in',\n",
       " '2016',\n",
       " 'https',\n",
       " ':',\n",
       " '//archive.org/details/westvirginiamedi5619west',\n",
       " 'm',\n",
       " 'now',\n",
       " 'ium',\n",
       " '(',\n",
       " '£',\n",
       " ')',\n",
       " '(',\n",
       " 'propionyl',\n",
       " 'erythromycin',\n",
       " 'ester',\n",
       " ',',\n",
       " 'lilly',\n",
       " ')',\n",
       " \"'ey\",\n",
       " 'for',\n",
       " 'chjldre',\n",
       " 'too',\n",
       " '!',\n",
       " 'ilosone',\n",
       " '125',\n",
       " 'suspension',\n",
       " '(',\n",
       " 'propionyl',\n",
       " 'erythromycin',\n",
       " 'ester',\n",
       " 'lauryl',\n",
       " 'sulfate',\n",
       " ',',\n",
       " 'lilly',\n",
       " ')',\n",
       " 'deliciously',\n",
       " 'flavored',\n",
       " 'decisively',\n",
       " 'effective']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the tokens array, first fifty tokens\n",
    "journalTokens[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are many tokens in the array that are not words. The following lines will remove any token that does not contain a character from the alphabet. Further cleanup will be neceassary, for example, the \"digitized by\" stamp is still at the beginning of the text, and words broken by a column margin need to be re-concatenated, but for the sake of demonstration we will consider these results acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journalWords = [word for word in journalTokens if any([char for char in word if char.isalpha()])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will remove the stop words from this set of words. For an explanation of stop words, see the original blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load stopwords list from NLTK\n",
    "stopwords = nltk.corpus.stopwords.words(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove stopwords from journalWords\n",
    "journalStoppedWords = [word for word in journalWords if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bd',\n",
       " 'digitized',\n",
       " 'internet',\n",
       " 'archive',\n",
       " 'https',\n",
       " '//archive.org/details/westvirginiamedi5619west',\n",
       " 'ium',\n",
       " 'propionyl',\n",
       " 'erythromycin',\n",
       " 'ester',\n",
       " 'lilly',\n",
       " \"'ey\",\n",
       " 'chjldre',\n",
       " 'ilosone',\n",
       " 'suspension',\n",
       " 'propionyl',\n",
       " 'erythromycin',\n",
       " 'ester',\n",
       " 'lauryl',\n",
       " 'sulfate',\n",
       " 'lilly',\n",
       " 'deliciously',\n",
       " 'flavored',\n",
       " 'decisively',\n",
       " 'effective',\n",
       " 'exceptionally',\n",
       " 'safe',\n",
       " '5-cc',\n",
       " 'teaspoonful',\n",
       " 'provides',\n",
       " 'ilosone',\n",
       " 'lauryl',\n",
       " 'sulfate',\n",
       " 'equivalent',\n",
       " 'mg.',\n",
       " 'erythromycin',\n",
       " 'base',\n",
       " 'activity',\n",
       " 'supplied',\n",
       " 'bottles',\n",
       " 'cc',\n",
       " 'eli',\n",
       " 'lilly',\n",
       " 'company',\n",
       " 'indianapolis',\n",
       " 'indiana',\n",
       " 'u.',\n",
       " 's.',\n",
       " 'i960',\n",
       " 'epilepsy']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the words array, first fifty tokens\n",
    "journalStoppedWords[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type-Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an array of only the unique tokens in the words array\n",
    "journalUniqueWords = set(journalStoppedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28345"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique words\n",
    "len(journalUniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278228"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of words\n",
    "len(journalStoppedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10187687795620858"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratio of unique words to total words\n",
    "len(journalUniqueWords)/len(journalStoppedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates a table of the number of occurances of a word in the words array\n",
    "journalFreqTable = nltk.FreqDist(journalStoppedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical   m.   d. virginia west  dr. state   j.  may meeting hospital medicine  new association   w. \n",
      "3513 2676 2228 1928 1906 1626 1271 1147 1054 1037 1012  969  949  947  936 \n"
     ]
    }
   ],
   "source": [
    "#display the top twenty results as tabular data\n",
    "journalFreqTable.tabulate(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a list of all four-grams in our words list\n",
    "#since the stop words are important in phrases, we will us the array that still contatins them\n",
    "fourGrams = list(nltk.ngrams(journalWords, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a frequency distribution of these four grams\n",
    "fourGramsFreqs = nltk.FreqDist(fourGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an array of the most common phrases\n",
    "mostCommon = fourGramsFreqs.most_common(40) #change number to decide number of most common to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'west', 'virginia', 'medical'), 400),\n",
       " (('west', 'virginia', 'medical', 'journal'), 394),\n",
       " (('of', 'the', 'west', 'virginia'), 351),\n",
       " (('the', 'west', 'virginia', 'state'), 327),\n",
       " (('west', 'virginia', 'state', 'medical'), 324),\n",
       " (('virginia', 'state', 'medical', 'association'), 285),\n",
       " (('a', 'member', 'of', 'the'), 161),\n",
       " (('the', 'american', 'medical', 'association'), 138),\n",
       " (('university', 'school', 'of', 'medicine'), 113),\n",
       " (('annual', 'meeting', 'of', 'the'), 112),\n",
       " (('will', 'be', 'held', 'at'), 103),\n",
       " (('the', 'state', 'medical', 'association'), 101),\n",
       " (('of', 'the', 'state', 'medical'), 97),\n",
       " (('woman’s', 'auxiliary', 'to', 'the'), 96),\n",
       " (('his', 'm.', 'd.', 'degree'), 85),\n",
       " (('the', 'woman’s', 'auxiliary', 'to'), 83),\n",
       " (('of', 'the', 'american', 'medical'), 80),\n",
       " (('m.', 'd.', 'degree', 'from'), 79),\n",
       " (('of', 'the', 'woman’s', 'auxiliary'), 78),\n",
       " (('be', 'held', 'at', 'the'), 78),\n",
       " (('the', 'house', 'of', 'delegates'), 77),\n",
       " (('of', 'the', 'department', 'of'), 74),\n",
       " (('meeting', 'of', 'the', 'west'), 73),\n",
       " (('the', 'west', 'virginia', 'university'), 73),\n",
       " (('received', 'his', 'm.', 'd.'), 72),\n",
       " (('was', 'held', 'at', 'the'), 71),\n",
       " (('per', 'cent', 'of', 'the'), 68),\n",
       " (('state', 'medical', 'association', 'and'), 66),\n",
       " (('at', 'the', 'greenbrier', 'in'), 65),\n",
       " (('virginia', 'university', 'school', 'of'), 64),\n",
       " (('will', 'be', 'held', 'in'), 63),\n",
       " (('west', 'virginia', 'university', 'school'), 63),\n",
       " (('the', 'members', 'of', 'the'), 61),\n",
       " (('to', 'the', 'publication', 'committee'), 61),\n",
       " (('may', 'be', 'obtained', 'by'), 61),\n",
       " (('submitted', 'to', 'the', 'publication'), 61),\n",
       " (('in', 'white', 'sulphur', 'springs'), 60),\n",
       " (('president', 'of', 'the', 'west'), 60),\n",
       " (('the', 'american', 'college', 'of'), 59),\n",
       " (('be', 'obtained', 'by', 'writing'), 59)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostCommon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stay tuned for more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
